CUDA 编程中的一些概念：

**warp** 本质上是一组线程。

+ 同步执行：一个warp包含了32个线程，这些线程执行的是相同的指令（SIMT的体现）。

+ 最小调度单位：GPU 的调度单元以 warp 为单位进行调度，而不是单个线程。这意味着整个 warp 会被分配到一个流多处理器（SM）上并一起执行。这遵循木桶效应，以最慢的线程为准。
+ 优化warp的行为，尽可能的提高cuda程序的性能。
+ SM上可以有有限多个warp被激活,应该尽可能的让更多的warp被激活，提高激活比例。

bank 冲突

+ 在同一个warp中有多个线程，这些线程使用sm上的共享内存(share memory,几十kb～几百kb) ,这个共享内存又是被分成多个bank（32bit）。当不同的线程去访问同一个bank上的不同地址，那就会出现冲突
+ 一个warp中的不同线程去访问不同bank,不会出现冲突

|          | bank 0 | bank 1 | bank 2 | bank 3 | ...... | bank 29 | bank 30 | bank 31 |
| -------- | ------ | ------ | ------ | ------ | ------ | ------- | ------- | ------- |
| warp 0   | 0      | 1      | 2      | 3      | .....  | 29      | 30      | 31      |
| warp 1   | 32     | 33     | 34     | 35     | .....  | 61      | 62      | 63      |
| warp 2   | 64     | 65     | 66     | 67     | ....   | 94      | 95      | 96      |
| warp 3   |        |        |        |        |        |         |         |         |
| ........ |        |        |        |        |        |         |         |         |
| warp 29  |        |        |        |        |        |         |         |         |
| warp 30  |        |        |        |        |        |         |         |         |
| warp 31  | 992    | 993    | 994    | 995    | ...... | 1021    | 1022    | 1023    |



1. **On Chip Memory**:
   - **Registers**: 每个线程私有的寄存器，速度非常快，数量有限。
   - **Shared Memory**: 同一个线程块（block）中的所有线程共享的内存，速度较快，容量有限，通常用于线程间的通信和协作。
   - **L1 Cache**: 一些较新的GPU架构（如Kepler、Maxwell、Pascal、Volta、Turing、Ampere等）在SM上集成了L1缓存，用于加速对全局内存的访问。
   - **L2 Cache**: 从Kepler架构开始，部分GPU型号在芯片上集成了L2缓存，所有SM共享这部分缓存。
2. **On Board Memory**:
   - **Global Memory**: 所有线程都可以访问的内存，容量大，速度相对较慢，用于存储大量的数据。
   - **Constant Memory**: 一种特殊的只读内存，用于存储常量数据，可以被所有线程访问。
   - **Texture Memory**: 另一种特殊的只读内存，用于存储纹理数据，提供了特定的寻址模式和缓存优化，通常用于图像处理和数组访问。

让每个线程去按列读取矩阵

